## Where do robots find what pages are on a website?

Hint:

What does disallow tell a robot?


SOLUTION:

So, this is the question I solved first which comes under easy category on CTFlearn.
It says "Where do robots find what pages are on a website" and a int given as well as what does disallow tell a robot.
For solving this, we must know there is a robots.txt file some websites.
The robots. txt file, also known as the robots exclusion protocol or standard, is a text file that tells web robots (most often search engines) which pages on your site to crawl.
It also tells web robots which pages not to crawl. Let's say a search engine is about to visit a site.

So for CTFlearn we can go to its robots.txt by : https://ctflearn.com/robots.txt.
Here we will find its written :

                 User-agent: *
                 Disallow: /70r3hnanldfspufdsoifnlds.html
                 
We got disallow and theres a .html site on this.

So we can now go to : CTFlearn.com/70r3hnanldfspufdsoifnlds.html and we will find the flag as :   CTFlearn{r0b0ts_4r3_th3_futur3}.

So by this way we can solve this problem, quite an easy one though you must know robots.txt can help you getsolution for many problems in a CTF.

FLAG:  CTFlearn{r0b0ts_4r3_th3_futur3}

                   
